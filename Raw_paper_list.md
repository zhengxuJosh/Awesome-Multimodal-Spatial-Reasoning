| Title                                                                                             | Authors       | Venue/Date       | Paper Link                                   | Code                                         |
|---------------------------------------------------------------------------------------------------|---------------|------------------|----------------------------------------------|----------------------------------------------|
| Thinking in space: How multimodal large language models see, remember, and recall spaces          | Yang *et al.*   | Arxiv 2024 (Dec) | [paper](https://arxiv.org/pdf/2412.14171)  | [code](https://github.com/vision-x-nyu/thinking-in-space) |       
| Spatialvlm: Endowing vision-language models with spatial reasoning capabilities | Chen *et al.* | CVPR 2024 | [paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Chen_SpatialVLM_Endowing_Vision-Language_Models_with_Spatial_Reasoning_Capabilities_CVPR_2024_paper.pdf) | [code](https://github.com/remyxai/VQASynth) |
| SpatialRGPT: Grounded Spatial Reasoning in Vision Language Models | Cheng *et al.* | Arxiv 2024 (Jun) | [paper](https://arxiv.org/pdf/2406.01584) | [code](https://www.anjiecheng.me/SpatialRGPT) |
